{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPLrTdY689jA+kZH1JpmN+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/23206-final-sign-language-recognition-in-video/blob/main/NN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S-6NZ4xp2Cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import os\n",
        "import math\n",
        "import sys\n",
        "import cv2\n",
        "import io\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/SU2/data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_ZzM02fp4Xr",
        "outputId": "b4cd1c3a-6881-4ae8-858e-b91fb750a955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/Strojove-uceni/23206-final-sign-language-recognition-in-video.git\n",
        "!git clone https://github.com/jiri99/SU_sign-language.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pX23BWZVlIm",
        "outputId": "bf6f2e6d-de11-4ae8-f0a2-f9b0f3045732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '23206-final-sign-language-recognition-in-video'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 164 (delta 13), reused 0 (delta 0), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (164/164), 2.59 MiB | 12.40 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = \"/content/23206-final-sign-language-recognition-in-video/\"\n",
        "sys.path.append(os.path.abspath(repo_path))"
      ],
      "metadata": {
        "id": "yIUcKraoqPaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from buffer import ParquetData\n",
        "# from CNN_draft import NpyFolderDataset"
      ],
      "metadata": {
        "id": "fY1mPQyuq0sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selected_landmark_indices = [33, 133, 159, 263, 46, 70, 4, 454, 234, 10, 338, 297, 332, 61, 291, 0, 78, 14, 317,\n",
        "#                              152, 155, 337, 299, 333, 69, 104, 68, 398]\n",
        "\n",
        "df_train = pd.read_csv(path + \"/train_mod.csv\", sep=\",\")\n",
        "df_train.head()\n",
        "\n",
        "# data_load = ParquetData()\n",
        "# data_load.read_all(path, df_train, selected_landmark_indices)"
      ],
      "metadata": {
        "id": "qC46hmsnp4d-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_load = NpyFolderDataset(path)\n",
        "path_tensor = path + \"/tensors\"\n",
        "\n",
        "npy_files = []\n",
        "labels = []\n",
        "class_to_idx = {}\n",
        "for idx, class_name in enumerate(sorted(os.listdir(path_tensor))):\n",
        "    class_dir = os.path.join(path_tensor, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        class_to_idx[class_name] = idx\n",
        "        for file in os.listdir(class_dir):\n",
        "            if file.endswith('.npy'):\n",
        "                npy_files.append(os.path.join(class_dir, file))\n",
        "                labels.append(idx)"
      ],
      "metadata": {
        "id": "SEtLYcu_V0rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_data = []\n",
        "\n",
        "for npy_file in npy_files:\n",
        "  sample = np.load(npy_file)\n",
        "  sample = np.expand_dims(sample.astype(np.float32), axis=3)\n",
        "  stacked_data.append(sample)"
      ],
      "metadata": {
        "id": "wFqsNg4dAM6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(stacked_data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kCOtM4yMFt9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data = np.stack(X_train_raw, axis=0)\n",
        "X_train = tensor_data.reshape((540, 420, 70, 70, 1))\n",
        "tensor_data = np.stack(X_test_raw, axis=0)\n",
        "X_test = tensor_data.reshape((60, 420, 70, 70, 1))"
      ],
      "metadata": {
        "id": "T9Jo-nYnX7D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y_train = np.stack(y_train_raw, axis=0)\n",
        "one_hot_encoded_train = pd.get_dummies(y_train_raw)\n",
        "Y_train = tf.convert_to_tensor(one_hot_encoded_train, dtype=tf.float32)\n",
        "one_hot_encoded_test = pd.get_dummies(y_test_raw)\n",
        "Y_test = tf.convert_to_tensor(one_hot_encoded_test, dtype=tf.float32)\n",
        "# Y_test = np.stack(y_test_raw, axis=0)"
      ],
      "metadata": {
        "id": "B-FnInXoGJvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJbjnqyPHMov",
        "outputId": "608e9270-3029-4877-abc1-89f235c27a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(540, 420, 70, 70, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXYkVHQ5X3L1",
        "outputId": "dc8f33d4-62e3-46d7-ea0b-34d10603ed36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([540, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stacked_data = []\n",
        "# stacked_sign = []\n",
        "\n",
        "# for key_sign in list(data_load.data.keys()):\n",
        "#   for key_participiant in list(data_load.data[key_sign].keys()):\n",
        "#     stacked_sign.append(key_sign)\n",
        "#     stacked_data.append(data_load.data[key_sign][key_participiant].tensor)\n",
        "\n",
        "# tensor_data = np.stack(stacked_data, axis=0)\n",
        "# X_train = tensor_data.reshape((len(stacked_sign), 420, 70, 70, 1))\n",
        "# stack_sign = np.stack(stacked_sign, axis=0)\n",
        "# one_hot_encoded = pd.get_dummies(stack_sign)\n",
        "# Y_train = tf.convert_to_tensor(one_hot_encoded, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "_UODx5O1IzyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_height = 70\n",
        "frame_width = 70\n",
        "channels = 1\n",
        "# classes_num = len(list(data_load.data.keys()))\n",
        "classes_num = 10\n",
        "sequence_length = 420\n",
        "\n",
        "# CNN model for spatial feature extraction\n",
        "cnn = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(frame_height, frame_width, channels)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten()\n",
        "])\n",
        "\n",
        "# Final model\n",
        "model = Sequential([\n",
        "    TimeDistributed(cnn, input_shape=(sequence_length, frame_height, frame_width, channels)),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(classes_num, activation='softmax')  # Assuming 10 classes for the classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FzVVO7T3p4g0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f5fde8-940a-4d87-9a0c-73d39d3ce200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDist  (None, 420, 6272)         92672     \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                1622272   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1719364 (6.56 MB)\n",
            "Trainable params: 1719364 (6.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can fit this model on your preprocessed data.\n",
        "# X_train would be your video data with shape (num_samples, sequence_length, frame_height, frame_width, channels)\n",
        "# Y_train would be your labels\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XDG6m0FIIsq",
        "outputId": "9f6ee64a-9d1b-466d-91a5-b7f32851cd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "135/135 [==============================] - 23s 73ms/step - loss: 1.3949 - accuracy: 0.2259\n",
            "Epoch 2/10\n",
            "135/135 [==============================] - 10s 72ms/step - loss: 1.3872 - accuracy: 0.2481\n",
            "Epoch 3/10\n",
            "135/135 [==============================] - 10s 73ms/step - loss: 1.3872 - accuracy: 0.2796\n",
            "Epoch 4/10\n",
            "135/135 [==============================] - 10s 73ms/step - loss: 1.3919 - accuracy: 0.2685\n",
            "Epoch 5/10\n",
            "135/135 [==============================] - 10s 73ms/step - loss: 1.2525 - accuracy: 0.3815\n",
            "Epoch 6/10\n",
            "135/135 [==============================] - 10s 72ms/step - loss: 0.9670 - accuracy: 0.5500\n",
            "Epoch 7/10\n",
            "135/135 [==============================] - 10s 72ms/step - loss: 0.7857 - accuracy: 0.6593\n",
            "Epoch 8/10\n",
            "135/135 [==============================] - 10s 72ms/step - loss: 0.6407 - accuracy: 0.7222\n",
            "Epoch 9/10\n",
            "135/135 [==============================] - 10s 72ms/step - loss: 0.5368 - accuracy: 0.7667\n",
            "Epoch 10/10\n",
            "135/135 [==============================] - 10s 73ms/step - loss: 0.4307 - accuracy: 0.8204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7db958114c10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test, batch_size=4)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXciCtKNepGg",
        "outputId": "d7a7f27a-86fb-4973-ebc3-0bb106a09abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 28ms/step - loss: 0.7827 - accuracy: 0.7333\n",
            "Test Loss: 0.7827401757240295\n",
            "Test Accuracy: 0.7333333492279053\n"
          ]
        }
      ]
    }
  ]
}